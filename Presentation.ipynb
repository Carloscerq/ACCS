{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWqL0xTYDYTX"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Primeiramente, vamos organizar algumas dependencias necessarias para a execucao do jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zD_PFY_cE2dc"
   },
   "source": [
    "## Baixando dependencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzEXyqonDw3X"
   },
   "source": [
    "Para o desenvolvimento do projeto, vamos utilizar as seguintes bibliotecas:\n",
    "\n",
    "- `pandas`: Para conseguir realizar operacoes em cima dos `Dataframes`\n",
    "- `matplotlib`: Para fazer plotagem de graficos\n",
    "- `seaborn`: Para ajudar com a plotagem dos graficos mais comuns\n",
    "- `skops`: Para gerar artefatos a partir dos modelos\n",
    "- `scikit-learn`: Para o treinamento dos modelos\n",
    "- `ydata-profiling`: Para realizar um profiling em cima dos dados, pegando insights\n",
    "- `statsmodels`: Para ajudar com contas\n",
    "- `numpy`: Para ajudar com contas\n",
    "\n",
    "Importando as libs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/carlos/.platformio/penv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/carlos/.platformio/penv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: skops in /home/carlos/.platformio/penv/lib/python3.12/site-packages (0.10.0)\n",
      "Requirement already satisfied: seaborn in /home/carlos/.platformio/penv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /home/carlos/.platformio/penv/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: ydata_profiling in /home/carlos/.platformio/penv/lib/python3.12/site-packages (4.8.3)\n",
      "Requirement already satisfied: scikit-learn in /home/carlos/.platformio/penv/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: pyqt6 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (6.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from skops) (0.23.4)\n",
      "Requirement already satisfied: tabulate>=0.8.8 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from skops) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from skops) (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: scipy<1.14,>=1.4.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (1.13.1)\n",
      "Requirement already satisfied: pydantic>=2 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (2.8.2)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (6.0.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (3.1.4)\n",
      "Requirement already satisfied: visions<0.7.7,>=0.7.5 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata_profiling) (0.7.6)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (0.1.12)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (0.12.4)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (4.66.4)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (1.12)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (0.14.2)\n",
      "Requirement already satisfied: typeguard<5,>=3 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (4.3.0)\n",
      "Requirement already satisfied: imagehash==4.3.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (1.9.3)\n",
      "Requirement already satisfied: dacite>=1.8 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (1.8.1)\n",
      "Requirement already satisfied: numba<1,>=0.56.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from ydata_profiling) (0.60.0)\n",
      "Requirement already satisfied: PyWavelets in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from imagehash==4.3.1->ydata_profiling) (1.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: PyQt6-sip<14,>=13.6 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from pyqt6) (13.6.0)\n",
      "Requirement already satisfied: PyQt6-Qt6<6.8.0,>=6.7.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from pyqt6) (6.7.2)\n",
      "Requirement already satisfied: filelock in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->skops) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->skops) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->skops) (4.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from jinja2<3.2,>=2.11.1->ydata_profiling) (2.1.5)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from numba<1,>=0.56.0->ydata_profiling) (0.43.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from pydantic>=2->ydata_profiling) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from pydantic>=2->ydata_profiling) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata_profiling) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata_profiling) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata_profiling) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata_profiling) (2024.6.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from statsmodels<1,>=0.13.2->ydata_profiling) (0.5.6)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata_profiling) (23.2.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /home/carlos/.platformio/penv/lib/python3.12/site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata_profiling) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas skops seaborn matplotlib ydata_profiling scikit-learn pyqt6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ewYBV_lPEijH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import skops.io as sio\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pickle\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4ZGtTEIEyWr"
   },
   "source": [
    "## Funcoes auxiliares\n",
    "\n",
    "\n",
    "1 - `plot_corr_graph`: Plota o grafico de correlacao\n",
    "  - Parametros:\n",
    "    - `df` (`pd.DataFrame`): `DataFrame` a ser plotado\n",
    "    - `name` (`str`): Nome do grafico (Opcional)\n",
    "  - Resposta:\n",
    "    - `None`: A funcao nao retorna nenhum valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IaekGnUjE7jF"
   },
   "outputs": [],
   "source": [
    "def plot_corr_graph(df: pd.DataFrame, name: str ='Correlation Matrix') -> None:\n",
    "  corr_matrix = df.corr()\n",
    "  plt.figure(figsize=(50, 50))\n",
    "  sns.heatmap(corr_matrix, cmap='bwr')\n",
    "  plt.title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGagYCDQFlun"
   },
   "source": [
    "2 - `get_top_abs_correlations`: Pega as colunas com as maiores correlacoes\n",
    "  - Parametros:\n",
    "    - `df` (`pd.DataFrame`): `DataFrame` a ser utilizado\n",
    "    - `n` (`int`): Numero de colunas a ser retornados\n",
    "  - Resposta:\n",
    "    - `pd.Series`: Nome das colunas a serem retornadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZOar3F6HFqsT"
   },
   "outputs": [],
   "source": [
    "def get_top_abs_correlations(df: pd.DataFrame, n: int = 5) -> pd.Series:\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "      for j in range(0, i+1):\n",
    "        labels_to_drop.add((cols[i], cols[j]))\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvGdnTCiIEAC"
   },
   "source": [
    "**DEPRECATE**\n",
    "\n",
    "3 - `calculate_precision`: Retorna algumas informacoes sobre o modelo\n",
    "  - Parametros:\n",
    "    - `y_test` (`pd.DataFrame`): `DataFrame` com dados de teste\n",
    "    - `y_pred` (`pd.DataFrame`): `DataFrame` com dados da previsao\n",
    "  - Resposta:\n",
    "    - `None`: Sem nenhuma resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Q44pGNGbIGcw"
   },
   "outputs": [],
   "source": [
    "def calculate_precision(y_test: pd.DataFrame, y_pred: pd.DataFrame) -> None:\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - `export_model`: Exporta o `skops` dos modelos\n",
    "    - Parametros:\n",
    "        - `model`: Modelo\n",
    "        - `model_name`: Nome a ser salvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(model, model_name):\n",
    "    with open(model_name + '.pkl', 'wb') as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HhQ2f3MIp8i"
   },
   "source": [
    "# Importacao dos dados\n",
    "\n",
    "Vamos utilizar o `dengue_sinan.csv` que esta no google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vhCZluHnI_PI"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    #\"/content/drive/MyDrive/ACCS/dengue_sinan.csv\",\n",
    "    #\"/content/dengue_sinan.csv\",\n",
    "    \"./dengue_sinan.csv\",\n",
    "    low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qpa6bXTaJI29"
   },
   "source": [
    "Como primeiro passo, vamos pegar alguns insights sobre o que estamos trabalhando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1718123744982,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "z_2fRimyJT5g",
    "outputId": "a8497889-1c48-43f7-d6be-3a91fdb71742"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620211, 148)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1718123744982,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "szqrvA8xJCb8",
    "outputId": "cde71324-1776-4352-95b8-a85de779c3b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 620211 entries, 0 to 620210\n",
      "Columns: 148 entries, NU_NOTIFIC to ID_CNS_SUS_HASHED\n",
      "dtypes: float64(115), int64(8), object(25)\n",
      "memory usage: 700.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3575,
     "status": "ok",
     "timestamp": 1718123748554,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "0r0BArz-JQCu",
    "outputId": "91db4bfb-4cac-47d6-b4fd-54a2db1e6702"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_NOTIFIC</th>\n",
       "      <th>TP_NOT</th>\n",
       "      <th>SEM_NOT</th>\n",
       "      <th>NU_ANO</th>\n",
       "      <th>SG_UF_NOT</th>\n",
       "      <th>ID_MUNICIP</th>\n",
       "      <th>ID_REGIONA</th>\n",
       "      <th>ID_UNIDADE</th>\n",
       "      <th>SEM_PRI</th>\n",
       "      <th>SOUNDEX</th>\n",
       "      <th>...</th>\n",
       "      <th>DT_TRANSDM</th>\n",
       "      <th>DT_TRANSRM</th>\n",
       "      <th>DT_TRANSRS</th>\n",
       "      <th>DT_TRANSSE</th>\n",
       "      <th>NU_LOTE_V</th>\n",
       "      <th>NU_LOTE_H</th>\n",
       "      <th>CS_FLXRET</th>\n",
       "      <th>FLXRECEBI</th>\n",
       "      <th>IDENT_MICR</th>\n",
       "      <th>MIGRADO_W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.202110e+05</td>\n",
       "      <td>620211.000000</td>\n",
       "      <td>620211.000000</td>\n",
       "      <td>620211.000000</td>\n",
       "      <td>620211.000000</td>\n",
       "      <td>620211.000000</td>\n",
       "      <td>619972.000000</td>\n",
       "      <td>6.196540e+05</td>\n",
       "      <td>620211.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620209.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.132800e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.635363e+05</td>\n",
       "      <td>2.000003</td>\n",
       "      <td>202089.455401</td>\n",
       "      <td>2020.719987</td>\n",
       "      <td>29.020938</td>\n",
       "      <td>292045.766950</td>\n",
       "      <td>1390.364726</td>\n",
       "      <td>4.224895e+06</td>\n",
       "      <td>202075.828657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.544726e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.592750e+05</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>267.587171</td>\n",
       "      <td>2.684069</td>\n",
       "      <td>0.694210</td>\n",
       "      <td>6983.781566</td>\n",
       "      <td>64.124777</td>\n",
       "      <td>2.537868e+06</td>\n",
       "      <td>528.878688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.285162e+07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>201552.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>110004.000000</td>\n",
       "      <td>1331.000000</td>\n",
       "      <td>3.500000e+01</td>\n",
       "      <td>20211.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>201922.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>291080.000000</td>\n",
       "      <td>1381.000000</td>\n",
       "      <td>2.505711e+06</td>\n",
       "      <td>201921.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.200500e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202106.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>291800.000000</td>\n",
       "      <td>1385.000000</td>\n",
       "      <td>2.802074e+06</td>\n",
       "      <td>202105.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.291650e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202330.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>292740.000000</td>\n",
       "      <td>1398.000000</td>\n",
       "      <td>6.602533e+06</td>\n",
       "      <td>202328.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.994664e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>202414.000000</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>530010.000000</td>\n",
       "      <td>6255.000000</td>\n",
       "      <td>9.999396e+06</td>\n",
       "      <td>202414.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.927400e+10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         NU_NOTIFIC         TP_NOT        SEM_NOT         NU_ANO  \\\n",
       "count  6.202110e+05  620211.000000  620211.000000  620211.000000   \n",
       "mean   1.635363e+05       2.000003  202089.455401    2020.719987   \n",
       "std    5.592750e+05       0.001796     267.587171       2.684069   \n",
       "min    0.000000e+00       2.000000  201552.000000    2016.000000   \n",
       "25%    7.880000e+02       2.000000  201922.000000    2019.000000   \n",
       "50%    1.200500e+04       2.000000  202106.000000    2021.000000   \n",
       "75%    6.291650e+04       2.000000  202330.000000    2023.000000   \n",
       "max    9.994664e+06       3.000000  202414.000000    2024.000000   \n",
       "\n",
       "           SG_UF_NOT     ID_MUNICIP     ID_REGIONA    ID_UNIDADE  \\\n",
       "count  620211.000000  620211.000000  619972.000000  6.196540e+05   \n",
       "mean       29.020938  292045.766950    1390.364726  4.224895e+06   \n",
       "std         0.694210    6983.781566      64.124777  2.537868e+06   \n",
       "min        11.000000  110004.000000    1331.000000  3.500000e+01   \n",
       "25%        29.000000  291080.000000    1381.000000  2.505711e+06   \n",
       "50%        29.000000  291800.000000    1385.000000  2.802074e+06   \n",
       "75%        29.000000  292740.000000    1398.000000  6.602533e+06   \n",
       "max        53.000000  530010.000000    6255.000000  9.999396e+06   \n",
       "\n",
       "             SEM_PRI  SOUNDEX  ...  DT_TRANSDM  DT_TRANSRM  DT_TRANSRS  \\\n",
       "count  620211.000000      0.0  ...         0.0         0.0         0.0   \n",
       "mean   202075.828657      NaN  ...         NaN         NaN         NaN   \n",
       "std       528.878688      NaN  ...         NaN         NaN         NaN   \n",
       "min     20211.000000      NaN  ...         NaN         NaN         NaN   \n",
       "25%    201921.000000      NaN  ...         NaN         NaN         NaN   \n",
       "50%    202105.000000      NaN  ...         NaN         NaN         NaN   \n",
       "75%    202328.000000      NaN  ...         NaN         NaN         NaN   \n",
       "max    202414.000000      NaN  ...         NaN         NaN         NaN   \n",
       "\n",
       "       DT_TRANSSE  NU_LOTE_V  NU_LOTE_H      CS_FLXRET  FLXRECEBI  \\\n",
       "count         0.0        2.0        0.0  620209.000000        0.0   \n",
       "mean          NaN        0.0        NaN       0.378242        NaN   \n",
       "std           NaN        0.0        NaN       0.484949        NaN   \n",
       "min           NaN        0.0        NaN       0.000000        NaN   \n",
       "25%           NaN        0.0        NaN       0.000000        NaN   \n",
       "50%           NaN        0.0        NaN       0.000000        NaN   \n",
       "75%           NaN        0.0        NaN       1.000000        NaN   \n",
       "max           NaN        0.0        NaN       1.000000        NaN   \n",
       "\n",
       "         IDENT_MICR  MIGRADO_W  \n",
       "count  6.132800e+05        0.0  \n",
       "mean   9.544726e+04        NaN  \n",
       "std    5.285162e+07        NaN  \n",
       "min    2.000000e+00        NaN  \n",
       "25%    4.000000e+00        NaN  \n",
       "50%    4.000000e+00        NaN  \n",
       "75%    4.000000e+00        NaN  \n",
       "max    2.927400e+10        NaN  \n",
       "\n",
       "[8 rows x 123 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EeDxFYeJWS_"
   },
   "source": [
    "Assim, podemos ver que nosso `DataFrame` tem `148` colunas inicialmente com `620211` linhas.\n",
    "\n",
    "## Fazendo a limpeza inicial\n",
    "\n",
    "Como primeiro passo, podemos ver quais sao as colunas que tem **todos** os dados vazios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1718123749419,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "NkCoz6ooJR89",
    "outputId": "6852c78e-8850-4c1f-b0b2-09319d27fd9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOUNDEX esta vazia\n",
      "EVIDENCIA esta vazia\n",
      "CON_FHD esta vazia\n",
      "DT_TRANSUS esta vazia\n",
      "DT_TRANSDM esta vazia\n",
      "DT_TRANSRM esta vazia\n",
      "DT_TRANSRS esta vazia\n",
      "DT_TRANSSE esta vazia\n",
      "NU_LOTE_H esta vazia\n",
      "FLXRECEBI esta vazia\n",
      "MIGRADO_W esta vazia\n"
     ]
    }
   ],
   "source": [
    "nan_cols = []\n",
    "\n",
    "for col in df.columns:\n",
    "  if df[col].isnull().all():\n",
    "    nan_cols.append(col)\n",
    "    print(f'{col} esta vazia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HLm4ngxJ0nJ"
   },
   "source": [
    "Assim, podemos remover essas colunas que estao vazias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_6uZ0dXrJ5As"
   },
   "outputs": [],
   "source": [
    "df.drop(nan_cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jNhmrLUKCar"
   },
   "source": [
    "Depois disso, podemos nos livrar das colunas que tenham apenas valores constantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1332,
     "status": "ok",
     "timestamp": 1718123750740,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "qi9EewFgJ6mE",
    "outputId": "9b7bebed-ef49-4188-dff4-234e25cc99c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_AGRAVO apresenta valores constantes\n"
     ]
    }
   ],
   "source": [
    "const_cols = df.columns[df.nunique(dropna=False) <= 1]\n",
    "\n",
    "for col in const_cols:\n",
    "  print(f'{col} apresenta valores constantes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tC2j5fBrKRAs"
   },
   "source": [
    "Deletando essas tabelas com valores constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "k0uA0ZXuKO0c"
   },
   "outputs": [],
   "source": [
    "df.drop(const_cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_aVq478KX10"
   },
   "source": [
    "Podemos ver, agora, quantas tabelas removemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1718123751060,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "QURtUSl7KW4S",
    "outputId": "253ede32-0e9a-4c7f-ae9a-7d3e65cd5a66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620211, 136)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFNHK8TLKtNu"
   },
   "source": [
    "# Gerando relatorio\n",
    "\n",
    "Podemos utilizar o `ydata` para gerar um relatorio inicial sobre os nossos dados. Assim, geramos um `report.html` que pode conter informacoes importantes.\n",
    "\n",
    "**Atencao**: Essa celula pode demorar alguns minutos para rodar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "g0yHwR6dKexQ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a027e2ac48a2444fa92458633a4540ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/pandas/core/nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: 'M'')\n",
      "  warnings.warn(\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n",
      "/home/carlos/.platformio/penv/lib/python3.12/site-packages/ydata_profiling/model/pandas/duplicates_pandas.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  .reset_index(name=duplicates_key)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6109feaddf14ca3bb1dd807498b13ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd013ba815a84713ab99b1d969f4ce92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1c12ff064748329a2640e4823e0f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "profile.to_file('report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwSrMDQWRDsw"
   },
   "source": [
    "A partir do que investigamos no recurso a cima, podemos remover as seguintes colunas:\n",
    "\n",
    "- NU_LOTE_V: Apenas um valor nao nulo\n",
    "- NU_LOTE_I: Apenas um valor nao nulo\n",
    "- SG_UF: Todos os valores nao nulos iguais\n",
    "- ID_PAIS: Todos os valores nao nulos iguais\n",
    "- GENGIVO: Apenas dois valores nao nulos\n",
    "- METRO: Apenas dois valores nao nulos\n",
    "- SANGRAM: Apenas dois valores nao nulos\n",
    "- TP_NOT: Apenas um valor diferente dos demais\n",
    "- SG_UF: Todos os valores nao nulos iguais\n",
    "- ID_PAIS: Todos os valores nao nulos iguais\n",
    "- TP_SISTEMA: Todos os valores nao nulos iguais\n",
    "- NDUPLIC_N: Todos os valores nao nulos iguais\n",
    "- DT_TRANSSM: Todos os valores nao nulos iguais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "SiPyBCpcReZz"
   },
   "outputs": [],
   "source": [
    "df.drop([\n",
    "    'TP_NOT',\n",
    "    'SG_UF',\n",
    "    'ID_PAIS',\n",
    "    'NU_LOTE_I',\n",
    "    'TP_SISTEMA',\n",
    "    'NDUPLIC_N',\n",
    "    'DT_TRANSSM',\n",
    "    'NU_LOTE_V',\n",
    "    'GENGIVO',\n",
    "    'METRO',\n",
    "    'SANGRAM'\n",
    "], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf7Tth2KLreJ"
   },
   "source": [
    "# Transformando valores\n",
    "\n",
    "Vamos transformar valores entre `str` para `int` e `datetime`.\n",
    "\n",
    "- Para `datetime`:\n",
    "  - DT_SIN_PRI\n",
    "  - ID_OCUPA_N\n",
    "  - DT_INVEST\n",
    "  - DT_DIGITA\n",
    "  - DT_NOTIFIC\n",
    "  - DT_CHIK_S1\n",
    "  - DT_CHIK_S2\n",
    "  - DT_PRNT\n",
    "  - DT_SORO\n",
    "  - DT_NS1\n",
    "  - DT_VIRAL\n",
    "  - DT_INTERNA\n",
    "  - DT_OBITO\n",
    "  - DT_ALRM\n",
    "  - DT_GRAV\n",
    "  - DT_PCR\n",
    "  - DT_ENCERRA\n",
    "  - DT_TRANSSM\n",
    "\n",
    "- Para `int`:\n",
    "  - ID_OCUPA_N\n",
    "  - CS_SEXO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1281,
     "status": "ok",
     "timestamp": 1718123752667,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "nAlb2fGvLDYr",
    "outputId": "04f5c927-4d24-498b-fe94-a4ddcf1f6962"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23872/833572816.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "cols = [\n",
    "    'DT_SIN_PRI',\n",
    "    'ID_OCUPA_N',\n",
    "    'DT_INVEST',\n",
    "    'DT_DIGITA',\n",
    "    'DT_NOTIFIC',\n",
    "    'DT_CHIK_S1',\n",
    "    'DT_CHIK_S2',\n",
    "    'DT_PRNT',\n",
    "    'DT_SORO',\n",
    "    'DT_NS1',\n",
    "    'DT_VIRAL',\n",
    "    'DT_INTERNA',\n",
    "    'DT_OBITO',\n",
    "    'DT_ALRM',\n",
    "    'DT_GRAV',\n",
    "    'DT_PCR',\n",
    "    'DT_ENCERRA'\n",
    "]\n",
    "\n",
    "for col in cols:\n",
    "  df[col] = pd.to_datetime(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xX4bWkYSMa9G"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23872/3982873281.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['CS_SEXO'] = df['CS_SEXO'].replace({'M': 1, 'F': 0, 'I': 2})\n"
     ]
    }
   ],
   "source": [
    "df['ID_OCUPA_N'] = pd.to_numeric(df['ID_OCUPA_N'], errors='coerce')\n",
    "df['CS_SEXO'] = df['CS_SEXO'].replace({'M': 1, 'F': 0, 'I': 2})\n",
    "df['NM_REFEREN'] = pd.factorize(df['NM_REFEREN'])[0]\n",
    "df['NM_BAIRRO'] = pd.factorize(df['NM_BAIRRO'])[0]\n",
    "df['NOBAIINF'] = pd.factorize(df['NOBAIINF'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9L6AdTSMsAE"
   },
   "source": [
    "Removendo colunas de `str`\n",
    "\n",
    "- DS_OBS : Observacoes sobre o caso\n",
    "- ID_CNS_SUS_HASHED : ID Sus\n",
    "\n",
    "Podemos remover essa tabela por nao serem dados que vamos poder utilizar para o nosso desenvolvimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "xcAvOtwkMcaA"
   },
   "outputs": [],
   "source": [
    "df.drop([\n",
    "    'DS_OBS',\n",
    "    'ID_CNS_SUS_HASHED'\n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9InTHAusN93G"
   },
   "source": [
    "# Investigando\n",
    "\n",
    "## Corelacao\n",
    "\n",
    "Podemos comecar realizando a correlacao entre as variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23482,
     "status": "ok",
     "timestamp": 1718123776694,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "Y3pYMO7ROL58",
    "outputId": "903cd5c5-b445-456f-e140-5b1930359c6f"
   },
   "outputs": [],
   "source": [
    "plot_corr_graph(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5C6O850QTWO"
   },
   "source": [
    "Visualizando como tabela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16997,
     "status": "ok",
     "timestamp": 1718123793675,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "UtvugG93OMl1",
    "outputId": "f0f92264-c42e-4741-efc3-93dfd0f80e6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_NOTIFIC</th>\n",
       "      <th>DT_NOTIFIC</th>\n",
       "      <th>SEM_NOT</th>\n",
       "      <th>NU_ANO</th>\n",
       "      <th>SG_UF_NOT</th>\n",
       "      <th>ID_MUNICIP</th>\n",
       "      <th>ID_REGIONA</th>\n",
       "      <th>ID_UNIDADE</th>\n",
       "      <th>DT_SIN_PRI</th>\n",
       "      <th>SEM_PRI</th>\n",
       "      <th>...</th>\n",
       "      <th>EPISTAXE</th>\n",
       "      <th>PETEQUIAS</th>\n",
       "      <th>HEMATURA</th>\n",
       "      <th>LACO_N</th>\n",
       "      <th>PLASMATICO</th>\n",
       "      <th>PLAQ_MENOR</th>\n",
       "      <th>COMPLICA</th>\n",
       "      <th>DT_DIGITA</th>\n",
       "      <th>CS_FLXRET</th>\n",
       "      <th>IDENT_MICR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NU_NOTIFIC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031313</td>\n",
       "      <td>0.029076</td>\n",
       "      <td>0.026630</td>\n",
       "      <td>0.220976</td>\n",
       "      <td>0.223496</td>\n",
       "      <td>0.105601</td>\n",
       "      <td>-0.026054</td>\n",
       "      <td>0.021533</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.497249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.001026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_NOTIFIC</th>\n",
       "      <td>0.031313</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999295</td>\n",
       "      <td>0.996920</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.013376</td>\n",
       "      <td>0.086760</td>\n",
       "      <td>0.744571</td>\n",
       "      <td>0.509323</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.862609</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>-0.229100</td>\n",
       "      <td>-0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEM_NOT</th>\n",
       "      <td>0.029076</td>\n",
       "      <td>0.999295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>0.016088</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.084979</td>\n",
       "      <td>0.744096</td>\n",
       "      <td>0.509636</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.047573</td>\n",
       "      <td>-0.230101</td>\n",
       "      <td>-0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_ANO</th>\n",
       "      <td>0.026630</td>\n",
       "      <td>0.996920</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>0.015716</td>\n",
       "      <td>0.015036</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.742367</td>\n",
       "      <td>0.509149</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047498</td>\n",
       "      <td>-0.230737</td>\n",
       "      <td>-0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SG_UF_NOT</th>\n",
       "      <td>0.220976</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988639</td>\n",
       "      <td>0.536426</td>\n",
       "      <td>-0.010616</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001820</td>\n",
       "      <td>0.034225</td>\n",
       "      <td>-0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLAQ_MENOR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMPLICA</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_DIGITA</th>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>0.047573</td>\n",
       "      <td>0.047498</td>\n",
       "      <td>-0.001820</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.037301</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.936766</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030260</td>\n",
       "      <td>-0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS_FLXRET</th>\n",
       "      <td>0.003735</td>\n",
       "      <td>-0.229100</td>\n",
       "      <td>-0.230101</td>\n",
       "      <td>-0.230737</td>\n",
       "      <td>0.034225</td>\n",
       "      <td>0.023313</td>\n",
       "      <td>0.019867</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>-0.167251</td>\n",
       "      <td>-0.116386</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.030260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDENT_MICR</th>\n",
       "      <td>0.001026</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>-0.030456</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            NU_NOTIFIC  DT_NOTIFIC   SEM_NOT    NU_ANO  SG_UF_NOT  ID_MUNICIP  \\\n",
       "NU_NOTIFIC    1.000000    0.031313  0.029076  0.026630   0.220976    0.223496   \n",
       "DT_NOTIFIC    0.031313    1.000000  0.999295  0.996920   0.009270    0.016407   \n",
       "SEM_NOT       0.029076    0.999295  1.000000  0.999143   0.009248    0.016088   \n",
       "NU_ANO        0.026630    0.996920  0.999143  1.000000   0.009226    0.015716   \n",
       "SG_UF_NOT     0.220976    0.009270  0.009248  0.009226   1.000000    0.988639   \n",
       "...                ...         ...       ...       ...        ...         ...   \n",
       "PLAQ_MENOR    1.000000   -1.000000 -1.000000       NaN        NaN    1.000000   \n",
       "COMPLICA     -1.000000   -1.000000 -1.000000       NaN        NaN   -1.000000   \n",
       "DT_DIGITA     0.002047    0.047618  0.047573  0.047498  -0.001820   -0.000126   \n",
       "CS_FLXRET     0.003735   -0.229100 -0.230101 -0.230737   0.034225    0.023313   \n",
       "IDENT_MICR    0.001026   -0.000261 -0.000204 -0.000144  -0.000054    0.000161   \n",
       "\n",
       "            ID_REGIONA  ID_UNIDADE  DT_SIN_PRI   SEM_PRI  ...  EPISTAXE  \\\n",
       "NU_NOTIFIC    0.105601   -0.026054    0.021533  0.010667  ...      -1.0   \n",
       "DT_NOTIFIC    0.013376    0.086760    0.744571  0.509323  ...       1.0   \n",
       "SEM_NOT       0.014159    0.084979    0.744096  0.509636  ...       1.0   \n",
       "NU_ANO        0.015036    0.083000    0.742367  0.509149  ...       NaN   \n",
       "SG_UF_NOT     0.536426   -0.010616    0.007662  0.005276  ...       NaN   \n",
       "...                ...         ...         ...       ...  ...       ...   \n",
       "PLAQ_MENOR    1.000000    1.000000   -1.000000 -1.000000  ...      -1.0   \n",
       "COMPLICA     -1.000000   -1.000000   -1.000000 -1.000000  ...       NaN   \n",
       "DT_DIGITA     0.002813    0.000703    0.037301  0.024354  ...       1.0   \n",
       "CS_FLXRET     0.019867    0.009835   -0.167251 -0.116386  ...      -1.0   \n",
       "IDENT_MICR   -0.000095   -0.000575   -0.000135 -0.000060  ...       NaN   \n",
       "\n",
       "            PETEQUIAS  HEMATURA  LACO_N  PLASMATICO  PLAQ_MENOR  COMPLICA  \\\n",
       "NU_NOTIFIC        1.0       1.0     1.0   -0.497249         1.0      -1.0   \n",
       "DT_NOTIFIC       -1.0      -1.0    -1.0    0.862609        -1.0      -1.0   \n",
       "SEM_NOT          -1.0      -1.0    -1.0    0.866025        -1.0      -1.0   \n",
       "NU_ANO            NaN       NaN     NaN         NaN         NaN       NaN   \n",
       "SG_UF_NOT         NaN       NaN     NaN         NaN         NaN       NaN   \n",
       "...               ...       ...     ...         ...         ...       ...   \n",
       "PLAQ_MENOR        1.0       1.0     1.0   -1.000000         1.0       NaN   \n",
       "COMPLICA          NaN       NaN     NaN         NaN         NaN       1.0   \n",
       "DT_DIGITA        -1.0      -1.0    -1.0    0.936766        -1.0      -1.0   \n",
       "CS_FLXRET         1.0       1.0     1.0   -1.000000         1.0       1.0   \n",
       "IDENT_MICR        NaN       NaN     NaN         NaN         NaN       NaN   \n",
       "\n",
       "            DT_DIGITA  CS_FLXRET  IDENT_MICR  \n",
       "NU_NOTIFIC   0.002047   0.003735    0.001026  \n",
       "DT_NOTIFIC   0.047618  -0.229100   -0.000261  \n",
       "SEM_NOT      0.047573  -0.230101   -0.000204  \n",
       "NU_ANO       0.047498  -0.230737   -0.000144  \n",
       "SG_UF_NOT   -0.001820   0.034225   -0.000054  \n",
       "...               ...        ...         ...  \n",
       "PLAQ_MENOR  -1.000000   1.000000         NaN  \n",
       "COMPLICA    -1.000000   1.000000         NaN  \n",
       "DT_DIGITA    1.000000  -0.030260   -0.000261  \n",
       "CS_FLXRET   -0.030260   1.000000   -0.030456  \n",
       "IDENT_MICR  -0.000261  -0.030456    1.000000  \n",
       "\n",
       "[123 rows x 123 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_UcNWNaV-se"
   },
   "source": [
    "Podemos utilizar `get_top_abs_correlations` para pegar as correlacoes com maior valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18769,
     "status": "ok",
     "timestamp": 1718123812430,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "MNdXa1UwQVEo",
    "outputId": "8e34305f-69f4-417c-a003-42af6379c5e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMUNINF    MANI_HEMOR    1.0\n",
      "ID_RG_RESI  PLASMATICO    1.0\n",
      "ID_REGIONA  PLASMATICO    1.0\n",
      "DT_PCR      PETEQUIAS     1.0\n",
      "NM_BAIRRO   EPISTAXE      1.0\n",
      "ID_MUNICIP  ID_LOGRADO    1.0\n",
      "ID_UNIDADE  PETEQUIAS     1.0\n",
      "            EPISTAXE      1.0\n",
      "NM_BAIRRO   PETEQUIAS     1.0\n",
      "ID_MUNICIP  HEMATURA      1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(get_top_abs_correlations(df, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej8kEuryWQt2"
   },
   "source": [
    "Podemos, agora, para automatizar o processo, gerar uma lista com esses valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21061,
     "status": "ok",
     "timestamp": 1718123833469,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "gqGspdBdWFFM",
    "outputId": "02208d7a-5d22-4bd2-da09-31c24145cdb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEM_NOT', 'NU_ANO', 'ID_MUNICIP', 'ID_DISTRIT', 'ID_LOGRADO', 'ID_GEO2', 'NM_REFEREN', 'DT_INVEST', 'MIALGIA', 'EXANTEMA', 'NAUSEA', 'DOR_COSTAS', 'ARTRALGIA', 'DT_CHIK_S1', 'DT_SORO', 'RESUL_PCR_', 'SOROTIPO', 'MUNICIPIO', 'COMUNINF', 'CODISINF', 'CRITERIO', 'EVOLUCAO', 'DT_ENCERRA', 'ALRM_ABDOM', 'ALRM_LETAR', 'ALRM_LIQ', 'GRAV_ENCH', 'GRAV_TAQUI', 'GRAV_EXTRE', 'GRAV_CONSC', 'GRAV_ORGAO', 'MANI_HEMOR', 'EPISTAXE', 'PETEQUIAS', 'HEMATURA', 'LACO_N', 'PLASMATICO', 'PLAQ_MENOR', 'COMPLICA', 'DT_DIGITA', 'CS_FLXRET']\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = df.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# Vamos filtrar tabelas com correlacao maior que 95%\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocH2KmwsWdJK"
   },
   "source": [
    "Assim, podemos remover as seguintes colunas:\n",
    "- SEM_NOT\n",
    "- NU_ANO\n",
    "- ID_MUNICIP\n",
    "- ID_DISTRIT\n",
    "- ID_LOGRADO\n",
    "- DT_INVEST\n",
    "- MIALGIA\n",
    "- EXANTEMA\n",
    "- NAUSEA\n",
    "- DOR_COSTAS\n",
    "- ARTRALGIA\n",
    "- DT_CHIK_S1\n",
    "- DT_SORO\n",
    "- RESUL_PCR_\n",
    "- SOROTIPO\n",
    "- MUNICIPIO\n",
    "- HOSPITAL\n",
    "- COMUNINF\n",
    "- CODISINF\n",
    "- CRITERIO\n",
    "- EVOLUCAO\n",
    "- DT_ENCERRA\n",
    "- ALRM_ABDOM\n",
    "- ALRM_LETAR\n",
    "- ALRM_LIQ\n",
    "- GRAV_ENCH\n",
    "- GRAV_TAQUI\n",
    "- GRAV_EXTRE\n",
    "- GRAV_CONSC\n",
    "- GRAV_ORGAO\n",
    "- MANI_HEMOR\n",
    "- EPISTAXE\n",
    "- PETEQUIAS\n",
    "- HEMATURA\n",
    "- LACO_N\n",
    "- PLASMATICO\n",
    "- PLAQ_MENOR\n",
    "- COMPLICA\n",
    "- DT_DIGITA\n",
    "- CS_FLXRET\n",
    "- UF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "i7pTnRh8WY2U"
   },
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "  'SEM_NOT',\n",
    "  'NU_ANO',\n",
    "  'ID_MUNICIP',\n",
    "  'ID_DISTRIT',\n",
    "  'ID_LOGRADO',\n",
    "  'ID_GEO2',\n",
    "  'DT_INVEST',\n",
    "  'MIALGIA',\n",
    "  'EXANTEMA',\n",
    "  'NAUSEA',\n",
    "  'DOR_COSTAS',\n",
    "  'ARTRALGIA',\n",
    "  'DT_CHIK_S1',\n",
    "  'DT_SORO',\n",
    "  'RESUL_PCR_',\n",
    "  'SOROTIPO',\n",
    "  'MUNICIPIO',\n",
    "  'COMUNINF',\n",
    "  'CODISINF',\n",
    "  'CRITERIO',\n",
    "  'EVOLUCAO',\n",
    "  'DT_ENCERRA',\n",
    "  'ALRM_ABDOM',\n",
    "  'ALRM_LETAR',\n",
    "  'ALRM_LIQ',\n",
    "  'GRAV_ENCH',\n",
    "  'GRAV_TAQUI',\n",
    "  'GRAV_EXTRE',\n",
    "  'GRAV_CONSC',\n",
    "  'GRAV_ORGAO',\n",
    "  'MANI_HEMOR',\n",
    "  'EPISTAXE',\n",
    "  'PETEQUIAS',\n",
    "  'HEMATURA',\n",
    "  'LACO_N',\n",
    "  'PLASMATICO',\n",
    "  'PLAQ_MENOR',\n",
    "  'COMPLICA',\n",
    "  'DT_DIGITA',\n",
    "  'CS_FLXRET',\n",
    "  'HOSPITAL',\n",
    "  'UF'\n",
    "]\n",
    "\n",
    "df.drop(to_drop, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15459,
     "status": "ok",
     "timestamp": 1718123848898,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "5KAZJRaZWgNf",
    "outputId": "f9d2c2db-b80e-41df-d8cc-358ababfbc6f"
   },
   "outputs": [],
   "source": [
    "plot_corr_graph(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H_c__TOW0sH"
   },
   "source": [
    "# Tratando valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1718123848899,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "e-wwOgVjWjuN",
    "outputId": "3783e058-017e-40e0-b53b-d6c0910b4582"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NU_NOTIFIC', 'DT_NOTIFIC', 'SG_UF_NOT', 'ID_REGIONA', 'ID_UNIDADE',\n",
       "       'DT_SIN_PRI', 'SEM_PRI', 'NU_IDADE_N', 'CS_SEXO', 'CS_GESTANT',\n",
       "       'CS_RACA', 'CS_ESCOL_N', 'ID_MN_RESI', 'ID_RG_RESI', 'ID_BAIRRO',\n",
       "       'NM_BAIRRO', 'ID_GEO1', 'NM_REFEREN', 'CS_ZONA', 'ID_OCUPA_N', 'FEBRE',\n",
       "       'CEFALEIA', 'VOMITO', 'CONJUNTVIT', 'ARTRITE', 'PETEQUIA_N',\n",
       "       'LEUCOPENIA', 'LACO', 'DOR_RETRO', 'DIABETES', 'HEMATOLOG', 'HEPATOPAT',\n",
       "       'RENAL', 'HIPERTENSA', 'ACIDO_PEPT', 'AUTO_IMUNE', 'DT_CHIK_S2',\n",
       "       'DT_PRNT', 'RES_CHIKS1', 'RES_CHIKS2', 'RESUL_PRNT', 'RESUL_SORO',\n",
       "       'DT_NS1', 'RESUL_NS1', 'DT_VIRAL', 'RESUL_VI_N', 'DT_PCR', 'HISTOPA_N',\n",
       "       'IMUNOH_N', 'HOSPITALIZ', 'DT_INTERNA', 'DDD_HOSP', 'TEL_HOSP',\n",
       "       'TPAUTOCTO', 'COUFINF', 'COPAISINF', 'CO_BAINF', 'NOBAIINF',\n",
       "       'CLASSI_FIN', 'DOENCA_TRA', 'CLINC_CHIK', 'DT_OBITO', 'ALRM_HIPOT',\n",
       "       'ALRM_PLAQ', 'ALRM_VOM', 'ALRM_SANG', 'ALRM_HEMAT', 'ALRM_HEPAT',\n",
       "       'DT_ALRM', 'GRAV_PULSO', 'GRAV_CONV', 'GRAV_INSUF', 'GRAV_HIPOT',\n",
       "       'GRAV_HEMAT', 'GRAV_MELEN', 'GRAV_METRO', 'GRAV_SANG', 'GRAV_AST',\n",
       "       'GRAV_MIOC', 'DT_GRAV', 'IDENT_MICR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb-zXWCEW6Tu"
   },
   "source": [
    "Inicialmente, podemos ver quais tabelas do nosso `DataFrame` apresentam valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1718123848899,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "rktdUbPNW4UN",
    "outputId": "f94a93fc-5cb2-4d4d-c201-38a0276973d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NU_NOTIFIC         0\n",
       "DT_NOTIFIC         0\n",
       "SG_UF_NOT          0\n",
       "ID_REGIONA       239\n",
       "ID_UNIDADE       557\n",
       "               ...  \n",
       "GRAV_SANG     619633\n",
       "GRAV_AST      619634\n",
       "GRAV_MIOC     619633\n",
       "DT_GRAV       619671\n",
       "IDENT_MICR      6931\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7At1ueAXEIN"
   },
   "source": [
    "Listando as tabelas que apresentam valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1718123848900,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "ctStWBq_W_st",
    "outputId": "8ff8dbb6-0837-4dfc-fd80-390cc8ea2929"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID_REGIONA',\n",
       " 'ID_UNIDADE',\n",
       " 'DT_SIN_PRI',\n",
       " 'CS_SEXO',\n",
       " 'CS_GESTANT',\n",
       " 'CS_RACA',\n",
       " 'CS_ESCOL_N',\n",
       " 'ID_RG_RESI',\n",
       " 'ID_BAIRRO',\n",
       " 'ID_GEO1',\n",
       " 'CS_ZONA',\n",
       " 'FEBRE',\n",
       " 'CEFALEIA',\n",
       " 'VOMITO',\n",
       " 'CONJUNTVIT',\n",
       " 'ARTRITE',\n",
       " 'PETEQUIA_N',\n",
       " 'LEUCOPENIA',\n",
       " 'LACO',\n",
       " 'DOR_RETRO',\n",
       " 'DIABETES',\n",
       " 'HEMATOLOG',\n",
       " 'HEPATOPAT',\n",
       " 'RENAL',\n",
       " 'HIPERTENSA',\n",
       " 'ACIDO_PEPT',\n",
       " 'AUTO_IMUNE',\n",
       " 'DT_CHIK_S2',\n",
       " 'DT_PRNT',\n",
       " 'RES_CHIKS1',\n",
       " 'RES_CHIKS2',\n",
       " 'RESUL_PRNT',\n",
       " 'RESUL_SORO',\n",
       " 'DT_NS1',\n",
       " 'RESUL_NS1',\n",
       " 'DT_VIRAL',\n",
       " 'RESUL_VI_N',\n",
       " 'DT_PCR',\n",
       " 'HISTOPA_N',\n",
       " 'IMUNOH_N',\n",
       " 'HOSPITALIZ',\n",
       " 'DT_INTERNA',\n",
       " 'DDD_HOSP',\n",
       " 'TEL_HOSP',\n",
       " 'TPAUTOCTO',\n",
       " 'COUFINF',\n",
       " 'COPAISINF',\n",
       " 'CO_BAINF',\n",
       " 'CLASSI_FIN',\n",
       " 'DOENCA_TRA',\n",
       " 'CLINC_CHIK',\n",
       " 'DT_OBITO',\n",
       " 'ALRM_HIPOT',\n",
       " 'ALRM_PLAQ',\n",
       " 'ALRM_VOM',\n",
       " 'ALRM_SANG',\n",
       " 'ALRM_HEMAT',\n",
       " 'ALRM_HEPAT',\n",
       " 'DT_ALRM',\n",
       " 'GRAV_PULSO',\n",
       " 'GRAV_CONV',\n",
       " 'GRAV_INSUF',\n",
       " 'GRAV_HIPOT',\n",
       " 'GRAV_HEMAT',\n",
       " 'GRAV_MELEN',\n",
       " 'GRAV_METRO',\n",
       " 'GRAV_SANG',\n",
       " 'GRAV_AST',\n",
       " 'GRAV_MIOC',\n",
       " 'DT_GRAV',\n",
       " 'IDENT_MICR']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWCHe2hgXKWN"
   },
   "source": [
    "Para a coluna `CLASSI_FIN`, vamos remover aquelas que apresentam valor nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Z8trAUmGXGiK"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['CLASSI_FIN'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q8fagfSXQVl"
   },
   "source": [
    "Depois disso, podemos utilizar o `replace` para transformar os diversos valores em 0 caso o paciente nao tenha dengue e 1 caso o mesmo tenha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1718123849301,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "aJ9FRLtwXP21",
    "outputId": "72787fb3-134b-4464-e4fe-e66bfc3a5d9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8., 10.,  5.,  1.,  2., 12., 11.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CLASSI_FIN'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "H5OmRq_CXYA5"
   },
   "outputs": [],
   "source": [
    "df['CLASSI_FIN'] = df['CLASSI_FIN'].replace(5, 0)\n",
    "df['CLASSI_FIN'] = df['CLASSI_FIN'].replace(8, 0)\n",
    "df['CLASSI_FIN'] = df['CLASSI_FIN'].replace(1, 0)\n",
    "df['CLASSI_FIN'] = df['CLASSI_FIN'].replace(2, 0)\n",
    "df['CLASSI_FIN'] = df['CLASSI_FIN'].replace(10, 1)\n",
    "df['CLASSI_FIN'] = df['CLASSI_FIN'].replace(11, 1)\n",
    "df['CLASSI_FIN'] = df['CLASSI_FIN'].replace(12, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb1OmHeBXvhU"
   },
   "source": [
    "Vamos agora tratar os campos restantes de forma individual\n",
    "\n",
    "Para os campos:\n",
    "\n",
    "- ID_REGIONA\n",
    "- ID_UNIDADE\n",
    "- ID_RG_RESI\n",
    "- ID_BAIRRO\n",
    "- DDD_HOSP\n",
    "- TEL_HOSP\n",
    "- ID_GEO1\n",
    "- CS_ZONA\n",
    "- COUFINF\n",
    "\n",
    "Vamos preencher utilizando como base, os valores nao nulos da tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "tTVQSFslXxpH"
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "  'ID_REGIONA',\n",
    "  'ID_UNIDADE',\n",
    "  'ID_RG_RESI',\n",
    "  'ID_BAIRRO',\n",
    "  'DDD_HOSP',\n",
    "  'TEL_HOSP',\n",
    "  'ID_GEO1',\n",
    "  'CS_ZONA',\n",
    "  'COUFINF'\n",
    "]\n",
    "\n",
    "for col in cols:\n",
    "  df[col] = df[col].ffill()\n",
    "  df[col] = df[col].bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwQNua5kYN21"
   },
   "source": [
    "Para os campos de sintomas, vamos colocar o valor `2` como padrao, ja que representa o nao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tRvRlKywYSBA"
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "  \"FEBRE\",\n",
    "  \"CEFALEIA\",\n",
    "  \"VOMITO\",\n",
    "  \"CONJUNTVIT\",\n",
    "  \"ARTRITE\",\n",
    "  \"PETEQUIA_N\",\n",
    "  \"LEUCOPENIA\",\n",
    "  \"LACO\",\n",
    "  \"DOR_RETRO\",\n",
    "  \"CLASSI_FIN\",\n",
    "  \"DIABETES\",\n",
    "  \"HEMATOLOG\",\n",
    "  'HEPATOPAT',\n",
    "  'RENAL',\n",
    "  'HIPERTENSA',\n",
    "  'ACIDO_PEPT',\n",
    "  'AUTO_IMUNE',\n",
    "  'GRAV_PULSO',\n",
    "  'GRAV_CONV',\n",
    "  'GRAV_INSUF',\n",
    "  'GRAV_HIPOT',\n",
    "  'GRAV_HEMAT',\n",
    "  'GRAV_MELEN',\n",
    "  'GRAV_METRO',\n",
    "  'GRAV_SANG',\n",
    "  'GRAV_AST',\n",
    "  'GRAV_MIOC',\n",
    "  'ALRM_HIPOT',\n",
    "  'ALRM_PLAQ',\n",
    "  'ALRM_VOM',\n",
    "  'ALRM_SANG',\n",
    "  'ALRM_HEMAT',\n",
    "  'ALRM_HEPAT',\n",
    "  'DOENCA_TRA',\n",
    "  'RESUL_VI_N',\n",
    "]\n",
    "\n",
    "for col in cols:\n",
    "  df[col] = df[col].fillna(2)\n",
    "  df[col] = df[col].replace(2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLio0xsAYY9d"
   },
   "source": [
    "Colocando não realizado para valores nulos do resultados dos exames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "o65dNoWPYUeu"
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "  'RES_CHIKS1',\n",
    "  'RES_CHIKS2',\n",
    "  'RESUL_PRNT',\n",
    "  'RESUL_SORO',\n",
    "  'RESUL_NS1',\n",
    "  'IMUNOH_N',\n",
    "  'HISTOPA_N'\n",
    "]\n",
    "\n",
    "for col in cols:\n",
    "  df[col] = df[col].fillna(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kKJqModYbQs"
   },
   "source": [
    "Colocando o valor `0` para `CLINIC_CHIK`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "DAIZ0wvdYayM"
   },
   "outputs": [],
   "source": [
    "df['CLINC_CHIK'] = df['CLINC_CHIK'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIzU2D6kYe7c"
   },
   "source": [
    "Tratando datas colocando o valor 0 da epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "YGPtpJJRYiN6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
      "/tmp/ipykernel_23872/3444795586.py:18: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n"
     ]
    }
   ],
   "source": [
    "cols = [\n",
    "  'DT_SIN_PRI',\n",
    "  'DT_CHIK_S2',\n",
    "  'DT_PRNT',\n",
    "  'DT_NS1',\n",
    "  'DT_VIRAL',\n",
    "  'DT_PCR',\n",
    "  'DT_OBITO',\n",
    "  'DT_ALRM',\n",
    "  'DT_GRAV',\n",
    "  'DT_INTERNA',\n",
    "  'DT_NOTIFIC'\n",
    "]\n",
    "\n",
    "start_date = pd.to_datetime('1970-01-01')\n",
    "\n",
    "for col in cols:\n",
    "  df[col] = pd.to_datetime(df[col], errors='coerce').view('int64')\n",
    "  df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gbl17qt4YgZL"
   },
   "source": [
    "Colocando valores padroes nos campos `CS_*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "W5zxwbfZYlU6"
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "  'CS_SEXO',\n",
    "  'CS_GESTANT',\n",
    "  'CS_RACA',\n",
    "  'CS_ESCOL_N',\n",
    "]\n",
    "\n",
    "for col in cols:\n",
    "  df[col] = df[col].fillna(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QNq5RntYoqn"
   },
   "source": [
    "Colocando o valor padrao como nao (`2`)  para `HOSPITALIZ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "m6En6YIBYmjx"
   },
   "outputs": [],
   "source": [
    "df['HOSPITALIZ'] = df['HOSPITALIZ'].fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "poTr5zeeYqe3"
   },
   "outputs": [],
   "source": [
    "df['TPAUTOCTO'] = df['TPAUTOCTO'].fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcuEQLrZYx4K"
   },
   "source": [
    "Colocando o valor padrao como `1` para `COPAISINF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "uHi01s4aYwXd"
   },
   "outputs": [],
   "source": [
    "df['COPAISINF'] = df['COPAISINF'].fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cgh9C3tY1PQ"
   },
   "source": [
    "Colocando o valor padrao para `CO_BAINF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "cfxQHL7CYzX2"
   },
   "outputs": [],
   "source": [
    "df['CO_BAINF'] = df['CO_BAINF'].fillna(df['CO_BAINF'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8ESkdKQY4wX"
   },
   "source": [
    "Colocando a moda como valor padrao para `IDENT_MICR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "sH0fOYKLY2y4"
   },
   "outputs": [],
   "source": [
    "df['IDENT_MICR'] = df['IDENT_MICR'].fillna(df['IDENT_MICR'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iH9B0tDQY7-n"
   },
   "source": [
    "Agora, podemos verificar que tratamos todas as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1718123849303,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "fCRL_hUkY6hO",
    "outputId": "78a48a36-2de3-4316-f683-32b2b455f0c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1718123849752,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "UpdLlEDyZKAd",
    "outputId": "24520d54-39f4-4d8d-e393-ca22ed8c7627"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_NOTIFIC</th>\n",
       "      <th>DT_NOTIFIC</th>\n",
       "      <th>SG_UF_NOT</th>\n",
       "      <th>ID_REGIONA</th>\n",
       "      <th>ID_UNIDADE</th>\n",
       "      <th>DT_SIN_PRI</th>\n",
       "      <th>SEM_PRI</th>\n",
       "      <th>NU_IDADE_N</th>\n",
       "      <th>CS_SEXO</th>\n",
       "      <th>CS_GESTANT</th>\n",
       "      <th>...</th>\n",
       "      <th>GRAV_INSUF</th>\n",
       "      <th>GRAV_HIPOT</th>\n",
       "      <th>GRAV_HEMAT</th>\n",
       "      <th>GRAV_MELEN</th>\n",
       "      <th>GRAV_METRO</th>\n",
       "      <th>GRAV_SANG</th>\n",
       "      <th>GRAV_AST</th>\n",
       "      <th>GRAV_MIOC</th>\n",
       "      <th>DT_GRAV</th>\n",
       "      <th>IDENT_MICR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>1457136000000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>2498731.0</td>\n",
       "      <td>1456876800000000000</td>\n",
       "      <td>201609</td>\n",
       "      <td>3009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298</td>\n",
       "      <td>1455494400000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>3280969.0</td>\n",
       "      <td>1455408000000000000</td>\n",
       "      <td>201607</td>\n",
       "      <td>4039.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5082</td>\n",
       "      <td>1458864000000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>2800527.0</td>\n",
       "      <td>1458777600000000000</td>\n",
       "      <td>201612</td>\n",
       "      <td>4053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111262</td>\n",
       "      <td>1458777600000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>2706628.0</td>\n",
       "      <td>1458691200000000000</td>\n",
       "      <td>201612</td>\n",
       "      <td>4065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>1457827200000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>2498731.0</td>\n",
       "      <td>1457740800000000000</td>\n",
       "      <td>201610</td>\n",
       "      <td>4067.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NU_NOTIFIC           DT_NOTIFIC  SG_UF_NOT  ID_REGIONA  ID_UNIDADE  \\\n",
       "0         158  1457136000000000000         29      1381.0   2498731.0   \n",
       "1         298  1455494400000000000         29      1385.0   3280969.0   \n",
       "2        5082  1458864000000000000         29      1385.0   2800527.0   \n",
       "3      111262  1458777600000000000         29      1385.0   2706628.0   \n",
       "4         166  1457827200000000000         29      1381.0   2498731.0   \n",
       "\n",
       "            DT_SIN_PRI  SEM_PRI  NU_IDADE_N  CS_SEXO  CS_GESTANT  ...  \\\n",
       "0  1456876800000000000   201609      3009.0      1.0         6.0  ...   \n",
       "1  1455408000000000000   201607      4039.0      1.0         6.0  ...   \n",
       "2  1458777600000000000   201612      4053.0      0.0         5.0  ...   \n",
       "3  1458691200000000000   201612      4065.0      0.0         6.0  ...   \n",
       "4  1457740800000000000   201610      4067.0      0.0         6.0  ...   \n",
       "\n",
       "   GRAV_INSUF  GRAV_HIPOT  GRAV_HEMAT  GRAV_MELEN  GRAV_METRO  GRAV_SANG  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0        0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0        0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0        0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0        0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0        0.0   \n",
       "\n",
       "   GRAV_AST  GRAV_MIOC              DT_GRAV  IDENT_MICR  \n",
       "0       0.0        0.0 -9223372036854775808         4.0  \n",
       "1       0.0        0.0 -9223372036854775808         4.0  \n",
       "2       0.0        0.0 -9223372036854775808         4.0  \n",
       "3       0.0        0.0 -9223372036854775808         4.0  \n",
       "4       0.0        0.0 -9223372036854775808         4.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPFYwkf0ZAZh"
   },
   "source": [
    "## Exportando os dados\n",
    "\n",
    "vamos exportar os dados para `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1718123849753,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "X3NwUOk6lj-5",
    "outputId": "34fbc544-6681-4125-af13-ab92c67185c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1457136000000000000\n",
       "1    1455494400000000000\n",
       "2    1458864000000000000\n",
       "3    1458777600000000000\n",
       "4    1457827200000000000\n",
       "Name: DT_NOTIFIC, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DT_NOTIFIC'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "HHxAr6cnccrJ"
   },
   "outputs": [],
   "source": [
    "df_tmp = df.copy()\n",
    "\n",
    "cols = [\n",
    "  'DT_SIN_PRI',\n",
    "  'DT_CHIK_S2',\n",
    "  'DT_PRNT',\n",
    "  'DT_NS1',\n",
    "  'DT_VIRAL',\n",
    "  'DT_PCR',\n",
    "  'DT_OBITO',\n",
    "  'DT_ALRM',\n",
    "  'DT_GRAV',\n",
    "  'DT_INTERNA',\n",
    "  'DT_NOTIFIC'\n",
    "]\n",
    "\n",
    "for col in cols:\n",
    "  df_tmp[col] = pd.to_datetime(df_tmp[col], errors='coerce', unit='ns')\n",
    "\n",
    "df_tmp.to_csv('out.csv', index=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1718123881056,
     "user": {
      "displayName": "Carlos Eduardo da Silva Cerqueira",
      "userId": "07090745159977828532"
     },
     "user_tz": 180
    },
    "id": "M6McHGyQkHYj",
    "outputId": "7fc294a0-fadf-4b20-9166-fab37b7254a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_NOTIFIC</th>\n",
       "      <th>DT_NOTIFIC</th>\n",
       "      <th>SG_UF_NOT</th>\n",
       "      <th>ID_REGIONA</th>\n",
       "      <th>ID_UNIDADE</th>\n",
       "      <th>DT_SIN_PRI</th>\n",
       "      <th>SEM_PRI</th>\n",
       "      <th>NU_IDADE_N</th>\n",
       "      <th>CS_SEXO</th>\n",
       "      <th>CS_GESTANT</th>\n",
       "      <th>...</th>\n",
       "      <th>GRAV_INSUF</th>\n",
       "      <th>GRAV_HIPOT</th>\n",
       "      <th>GRAV_HEMAT</th>\n",
       "      <th>GRAV_MELEN</th>\n",
       "      <th>GRAV_METRO</th>\n",
       "      <th>GRAV_SANG</th>\n",
       "      <th>GRAV_AST</th>\n",
       "      <th>GRAV_MIOC</th>\n",
       "      <th>DT_GRAV</th>\n",
       "      <th>IDENT_MICR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>29</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>2498731.0</td>\n",
       "      <td>2016-03-02</td>\n",
       "      <td>201609</td>\n",
       "      <td>3009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298</td>\n",
       "      <td>2016-02-15</td>\n",
       "      <td>29</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>3280969.0</td>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>201607</td>\n",
       "      <td>4039.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5082</td>\n",
       "      <td>2016-03-25</td>\n",
       "      <td>29</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>2800527.0</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>201612</td>\n",
       "      <td>4053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111262</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>29</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>2706628.0</td>\n",
       "      <td>2016-03-23</td>\n",
       "      <td>201612</td>\n",
       "      <td>4065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>2016-03-13</td>\n",
       "      <td>29</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>2498731.0</td>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>201610</td>\n",
       "      <td>4067.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NU_NOTIFIC DT_NOTIFIC  SG_UF_NOT  ID_REGIONA  ID_UNIDADE DT_SIN_PRI  \\\n",
       "0         158 2016-03-05         29      1381.0   2498731.0 2016-03-02   \n",
       "1         298 2016-02-15         29      1385.0   3280969.0 2016-02-14   \n",
       "2        5082 2016-03-25         29      1385.0   2800527.0 2016-03-24   \n",
       "3      111262 2016-03-24         29      1385.0   2706628.0 2016-03-23   \n",
       "4         166 2016-03-13         29      1381.0   2498731.0 2016-03-12   \n",
       "\n",
       "   SEM_PRI  NU_IDADE_N  CS_SEXO  CS_GESTANT  ...  GRAV_INSUF  GRAV_HIPOT  \\\n",
       "0   201609      3009.0      1.0         6.0  ...         0.0         0.0   \n",
       "1   201607      4039.0      1.0         6.0  ...         0.0         0.0   \n",
       "2   201612      4053.0      0.0         5.0  ...         0.0         0.0   \n",
       "3   201612      4065.0      0.0         6.0  ...         0.0         0.0   \n",
       "4   201610      4067.0      0.0         6.0  ...         0.0         0.0   \n",
       "\n",
       "   GRAV_HEMAT  GRAV_MELEN  GRAV_METRO  GRAV_SANG  GRAV_AST  GRAV_MIOC  \\\n",
       "0         0.0         0.0         0.0        0.0       0.0        0.0   \n",
       "1         0.0         0.0         0.0        0.0       0.0        0.0   \n",
       "2         0.0         0.0         0.0        0.0       0.0        0.0   \n",
       "3         0.0         0.0         0.0        0.0       0.0        0.0   \n",
       "4         0.0         0.0         0.0        0.0       0.0        0.0   \n",
       "\n",
       "   DT_GRAV  IDENT_MICR  \n",
       "0      NaT         4.0  \n",
       "1      NaT         4.0  \n",
       "2      NaT         4.0  \n",
       "3      NaT         4.0  \n",
       "4      NaT         4.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "EHi3O2lzd5Ae"
   },
   "outputs": [],
   "source": [
    "df.to_csv('out_brute.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7jdvEAFvB-m"
   },
   "source": [
    "# Treinamento\n",
    "\n",
    "Para facilitar o processo de treinamento, vamos criar uma classe `TrainingModels` responsavel por realizar aplicar e realizar o treinamento dos modelos selecionados. Podemos alterar os valores dos parametros durante a inicializacao do objeto.\n",
    "\n",
    "Estão sendo utilizados os seguintes modelos:\n",
    "KNeighborsClassifier, DecisionTreeClassifier, RandomForestClassifier, LogisticRegression e MLPClassifier\n",
    "\n",
    "Respectivos hiperparâmetros estão setados no construtor da classe:\n",
    " `knn_neighbors = 5`, `knn_weights = 'uniform'`, `knn_metric = 'euclidean'`, `dt_criterion = 'entropy'`, `dt_min_samples_split = 2`,`rf_n_estimators = 100`, `rf_criterion = 'entropy'`,`logistic_max_iter = 100`, `logistic_penalty = 'l2'`,`logistic_solver = 'lbfgs'`, `mlp_hidden_layer_sizes = (100, 100)`, `mlp_activation = 'relu'`, `mlp_solver = 'adam'`,\n",
    "`mlp_learning_rate_init = 0.001`, `mlp_max_iter = 200`,`mlp_batch_size = 32`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Ds5J2Y0bpmwt"
   },
   "outputs": [],
   "source": [
    "class TrainingModels:\n",
    "  def __init__(\n",
    "    self,\n",
    "    knn_neighbors: int = 5,\n",
    "    knn_weights: str = 'uniform',\n",
    "    knn_metric: str = 'euclidean',\n",
    "    dt_criterion: str = 'entropy',\n",
    "    dt_min_samples_split: int = 2,\n",
    "    rf_n_estimators: int = 100,\n",
    "    rf_criterion: str = 'entropy',\n",
    "    rf_max_depth: int = None,\n",
    "    logistic_max_iter: int = 100,\n",
    "    logistic_penalty: str = 'l2',\n",
    "    logistic_solver: str = 'lbfgs',\n",
    "    mlp_hidden_layer_sizes: tuple[int, int] = (100, 100),\n",
    "    mlp_activation: str = 'relu',\n",
    "    mlp_solver: str = 'adam',\n",
    "    mlp_learning_rate_init: float = 0.001,\n",
    "    mlp_max_iter: int = 200,\n",
    "    mlp_batch_size: int = 32\n",
    "  ):\n",
    "    self.knn = KNeighborsClassifier(\n",
    "        n_neighbors=knn_neighbors,\n",
    "        weights=knn_weights,\n",
    "        metric=knn_metric\n",
    "      )\n",
    "    self.dt = DecisionTreeClassifier(\n",
    "        criterion=dt_criterion,\n",
    "        min_samples_split=dt_min_samples_split\n",
    "      )\n",
    "    self.rf = RandomForestClassifier(\n",
    "        n_estimators=rf_n_estimators,\n",
    "        criterion=rf_criterion,\n",
    "        max_depth=rf_max_depth\n",
    "      )\n",
    "    self.logistic = LogisticRegression(\n",
    "        max_iter=logistic_max_iter,\n",
    "        penalty=logistic_penalty,\n",
    "        solver=logistic_solver\n",
    "      )\n",
    "    self.mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=mlp_hidden_layer_sizes,\n",
    "        activation=mlp_activation,\n",
    "        solver=mlp_solver,\n",
    "        learning_rate_init=mlp_learning_rate_init,\n",
    "        max_iter=mlp_max_iter,\n",
    "        batch_size=mlp_batch_size\n",
    "      )\n",
    "\n",
    "  def fit(self, X_train: pd.DataFrame, y_train: pd.DataFrame) -> None:\n",
    "    print(\"Treinando Knn...\")\n",
    "    self.knn.fit(X_train, y_train)\n",
    "    print(\"Treinando DT...\")\n",
    "    self.dt.fit(X_train, y_train)\n",
    "    print(\"Treinando RF...\")\n",
    "    self.rf.fit(X_train, y_train)\n",
    "    print(\"Treinando Logistic...\")\n",
    "    self.logistic.fit(X_train, y_train)\n",
    "    print(\"Treinando MLP\")\n",
    "    self.mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "  def plot_metrics(self, X_test, y_test):\n",
    "        models = {'KNN': self.knn, 'Decision Tree': self.dt, 'Random Forest': self.rf, 'Logistic Regression': self.logistic, 'MLP': self.mlp}\n",
    "        #models = {'KNN': self.knn, 'Decision Tree': self.dt, 'Random Forest': self.rf, 'Logistic Regression': self.logistic}\n",
    "        metrics = {'Accuracy': accuracy_score, 'Precision': precision_score, 'Recall': recall_score, 'F1 Score': f1_score}\n",
    "        colors = ['b', 'g', 'r', 'c', 'm']\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        bar_width = 0.15\n",
    "        index = np.arange(len(models))\n",
    "        metric_values = {}\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            y_pred = model.predict(X_test)\n",
    "            metric_values[model_name] = [metric_func(y_test, y_pred) for metric_func in metrics.values()]\n",
    "\n",
    "            # Print confusion matrix\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            plt.figure(figsize=(5, 4))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "            plt.title(f'{model_name} Confusion Matrix')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.show()\n",
    "\n",
    "        for i, (metric_name, metric_color) in enumerate(zip(metrics.keys(), colors)):\n",
    "            plt.bar(index + i * bar_width, [metric_value[i] for metric_value in metric_values.values()], bar_width, label=metric_name, color=metric_color)\n",
    "\n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Model Metrics Comparison')\n",
    "        plt.xticks(index + bar_width * (len(metrics) - 1) / 2, models.keys())\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "  def _help_load_models(self, path):\n",
    "      with open(path, 'rb') as file:\n",
    "          return pickle.load(file)\n",
    "    \n",
    "  def load_models(self, knn: str, dt: str, rf: str, logistic: str, mlp: str):\n",
    "      self.knn = self._help_load_models(knn)\n",
    "      self.dt = self._help_load_models(dt)\n",
    "      self.rf = self._help_load_models(rf)\n",
    "      self.logistic = self._help_load_models(logistic)\n",
    "      self.mlp = self._help_load_models(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "sG78qSMivFPv"
   },
   "outputs": [],
   "source": [
    "models = TrainingModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "ER3KKOXQvIzi"
   },
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaled_features = scaler.fit_transform(df)\n",
    "\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=df.columns)\n",
    "\n",
    "X = df_scaled.drop([\"CLASSI_FIN\"], axis=1)\n",
    "y = df_scaled['CLASSI_FIN']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_we7nH_vOf0",
    "outputId": "0b306686-8fac-423e-d9f9-49e4ffd8a38a"
   },
   "outputs": [],
   "source": [
    "models.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzaUOcEIJWOF"
   },
   "source": [
    "Métricas avaliadas:\n",
    "\n",
    "- 'Accuracy',\n",
    "- 'Precision',\n",
    "- 'Recall',\n",
    "- 'F1 Score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJsVT-vsvQrW"
   },
   "outputs": [],
   "source": [
    "models.plot_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkbTR3MUWzIO"
   },
   "source": [
    "Assim, podemos ver que os algoritmos de `DecisionTree` e, principalmente, `RandomForest` sao os melhores algoritmos para o problema proposto. O que se encaixa com o que seria esperado para esse tipo de problema.\n",
    "\n",
    "Como possivel melhoria do sistema, seria possivel aumentar a quatidade de interacoes da regressao logistica na esperanca de termos um melhor resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model(models.mlp, \"mlp_pesos_padroes\")\n",
    "export_model(models.logistic, \"logistic_pesos_padroes\")\n",
    "export_model(models.knn, \"knn_pesos_padroes\")\n",
    "export_model(models.dt, \"dt_pesos_padroes\")\n",
    "export_model(models.rf, \"rf_pesos_padroes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecionando Parametros\n",
    "\n",
    "Vamos usar `RandomizedSearchCV` para tentar encontrar os melhores paremetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=param_dist, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# pegar por f1, curva rock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asssim, temos que os melhores valores sao:\n",
    "\n",
    "- `n_estimators`: 100\n",
    "- `max_depth`: None\n",
    "- `criterion`: entropy\n",
    "- `bootstrap`: True\n",
    "- `class_weight`: balanced\n",
    "- `max_features`: sqrt\n",
    "- `min_samples_leaf`: 1\n",
    "- `min_samples_split`: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_neighbors': [10, 20, 25, 30, 35, 40],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "random_search = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_dist, scoring='accuracy', random_state=42, verbose = 1)\n",
    "random_search.fit(X, y)\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asssim, temos que os melhores valores sao:\n",
    "\n",
    "- `n_neighbors`: 35\n",
    "- `weights`: distance\n",
    "- `metric`: manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [5, 10, 20]\n",
    "}\n",
    "random_search = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=param_dist, scoring='accuracy', random_state=42, verbose = 1)\n",
    "random_search.fit(X, y)\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asssim, temos que os melhores valores sao:\n",
    "\n",
    "- `criterion`: entropy\n",
    "- `min_samples_split`: 10\n",
    "- `splitter`: random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'penalty': ['l2', 'elasticnet', None],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'max_iter': [350, 400, 450, 500, 550, 600, 700, 800]\n",
    "}\n",
    "random_search = RandomizedSearchCV(LogisticRegression(), param_distributions=param_dist, scoring='accuracy', random_state=42, verbose = 1)\n",
    "random_search.fit(X, y)\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asssim, temos que os melhores valores sao:\n",
    "\n",
    "- `penalty`: l2\n",
    "- `solver`: lbfgs\n",
    "- `max_iter`: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(100, 100), (150, 150)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "    'learning_rate_init': [0.0001, 0.001],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'batch_size': [16, 32]\n",
    "}\n",
    "random_search = RandomizedSearchCV(MLPClassifier(), param_distributions=param_dist, scoring='accuracy', random_state=42, verbose = 1)\n",
    "random_search.fit(X, y)\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asssim, temos que os melhores valores sao:\n",
    "\n",
    "- `hidden_layer_sizes`: (150, 150)\n",
    "- `activation`: relu\n",
    "- `solver`: adam\n",
    "- `learning_rate_init`: 0.001\n",
    "- `max_iter`: 300\n",
    "- `batch_size`: 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_models = TrainingModels(\n",
    "    rf_n_estimators = 100,\n",
    "    rf_criterion = 'entropy',\n",
    "    rf_max_depth = None,\n",
    "    knn_neighbors = 35,\n",
    "    knn_weights = 'distance',\n",
    "    knn_metric = 'manhattan',\n",
    "    dt_criterion = 'entropy',\n",
    "    dt_min_samples_split = 10,\n",
    "    logistic_max_iter = 200,\n",
    "    logistic_penalty = 'l2',\n",
    "    logistic_solver = 'lbfgs',\n",
    "    mlp_hidden_layer_sizes = (150, 150),\n",
    "    mlp_activation = 'relu',\n",
    "    mlp_solver = 'adam',\n",
    "    mlp_learning_rate_init = 0.001,\n",
    "    mlp_max_iter = 300,\n",
    "    mlp_batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_models.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_models.plot_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model(new_models.mlp, \"mlp_parametros_livres\")\n",
    "export_model(new_models.logistic, \"logistic_parametros_livres\")\n",
    "export_model(new_models.knn, \"knn_parametros_livres\")\n",
    "export_model(new_models.dt, \"dt_parametros_livres\")\n",
    "export_model(new_models.rf, \"rf_parametros_livres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando os modelos exportados\n",
    "\n",
    "Podemos usar os modelos que exportamos a cima para treinar o uso de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = TrainingModels()\n",
    "models.load_models(knn=\"./knn_parametros_livres.pkl\",\n",
    "                   dt=\"./dt_parametros_livres.pkl\",\n",
    "                   rf=\"./rf_parametros_livres.pkl\",\n",
    "                   logistic=\"./logistic_parametros_livres.pkl\",\n",
    "                   mlp=\"./mlp_parametros_livres.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.plot_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando base de dados de testes\n",
    "\n",
    "Para isso, vamos utilizar o `d1.csv` para identificar o Dataset 1 e `d2.csv` para identificar o Dataset 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(\"d1.csv\")\n",
    "d2 = pd.read_csv(\"d2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEMATOLOG</th>\n",
       "      <th>HEMATURA</th>\n",
       "      <th>LACO</th>\n",
       "      <th>CEFALEIA</th>\n",
       "      <th>ID_GEO2</th>\n",
       "      <th>FEBRE</th>\n",
       "      <th>NAUSEA</th>\n",
       "      <th>PETEQUIAS</th>\n",
       "      <th>CONJUNTVIT</th>\n",
       "      <th>EPISTAXE</th>\n",
       "      <th>...</th>\n",
       "      <th>AUTO_IMUNE</th>\n",
       "      <th>HIPERTENSA</th>\n",
       "      <th>PLASMATICO</th>\n",
       "      <th>PETEQUIA_N</th>\n",
       "      <th>MIALGIA</th>\n",
       "      <th>LACO_N</th>\n",
       "      <th>ACIDO_PEPT</th>\n",
       "      <th>EXANTEMA</th>\n",
       "      <th>PLAQ_MENOR</th>\n",
       "      <th>CLASSI_FIN_BINARIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HEMATOLOG  HEMATURA  LACO  CEFALEIA  ID_GEO2  FEBRE  NAUSEA  PETEQUIAS  \\\n",
       "0       -1.0      -1.0  -1.0      -1.0     -1.0   -1.0    -1.0       -1.0   \n",
       "1       -1.0      -1.0  -1.0      -1.0     -1.0   -1.0    -1.0       -1.0   \n",
       "2        0.0      -1.0   0.0       1.0     -1.0    0.0     0.0       -1.0   \n",
       "3       -1.0      -1.0  -1.0      -1.0     -1.0   -1.0    -1.0       -1.0   \n",
       "4       -1.0      -1.0  -1.0      -1.0     -1.0   -1.0    -1.0       -1.0   \n",
       "\n",
       "   CONJUNTVIT  EPISTAXE  ...  AUTO_IMUNE  HIPERTENSA  PLASMATICO  PETEQUIA_N  \\\n",
       "0        -1.0      -1.0  ...        -1.0        -1.0        -1.0        -1.0   \n",
       "1        -1.0      -1.0  ...        -1.0        -1.0        -1.0        -1.0   \n",
       "2         0.0      -1.0  ...         0.0         0.0        -1.0         0.0   \n",
       "3        -1.0      -1.0  ...        -1.0        -1.0        -1.0        -1.0   \n",
       "4        -1.0      -1.0  ...        -1.0        -1.0        -1.0        -1.0   \n",
       "\n",
       "   MIALGIA  LACO_N  ACIDO_PEPT  EXANTEMA  PLAQ_MENOR  CLASSI_FIN_BINARIO  \n",
       "0     -1.0    -1.0        -1.0      -1.0        -1.0                 0.0  \n",
       "1     -1.0    -1.0        -1.0      -1.0        -1.0                 0.0  \n",
       "2      1.0    -1.0         0.0       0.0        -1.0                 1.0  \n",
       "3     -1.0    -1.0        -1.0      -1.0        -1.0                 1.0  \n",
       "4     -1.0    -1.0        -1.0      -1.0        -1.0                 0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HEMATOLOG', 'HEMATURA', 'LACO', 'CEFALEIA', 'ID_GEO2', 'FEBRE',\n",
       "       'NAUSEA', 'PETEQUIAS', 'CONJUNTVIT', 'EPISTAXE', 'MANI_HEMOR',\n",
       "       'DIABETES', 'ARTRALGIA', 'ARTRITE', 'LEUCOPENIA', 'DOR_COSTAS',\n",
       "       'DOR_RETRO', 'VOMITO', 'RENAL', 'HEPATOPAT', 'AUTO_IMUNE', 'HIPERTENSA',\n",
       "       'PLASMATICO', 'PETEQUIA_N', 'MIALGIA', 'LACO_N', 'ACIDO_PEPT',\n",
       "       'EXANTEMA', 'PLAQ_MENOR', 'CLASSI_FIN_BINARIO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALRM_HEMAT',\n",
       " 'ALRM_HEPAT',\n",
       " 'ALRM_HIPOT',\n",
       " 'ALRM_PLAQ',\n",
       " 'ALRM_SANG',\n",
       " 'ALRM_VOM',\n",
       " 'CLASSI_FIN',\n",
       " 'CLINC_CHIK',\n",
       " 'COPAISINF',\n",
       " 'COUFINF',\n",
       " 'CO_BAINF',\n",
       " 'CS_ESCOL_N',\n",
       " 'CS_GESTANT',\n",
       " 'CS_RACA',\n",
       " 'CS_SEXO',\n",
       " 'CS_ZONA',\n",
       " 'DDD_HOSP',\n",
       " 'DOENCA_TRA',\n",
       " 'DT_ALRM',\n",
       " 'DT_CHIK_S2',\n",
       " 'DT_GRAV',\n",
       " 'DT_INTERNA',\n",
       " 'DT_NOTIFIC',\n",
       " 'DT_NS1',\n",
       " 'DT_OBITO',\n",
       " 'DT_PCR',\n",
       " 'DT_PRNT',\n",
       " 'DT_SIN_PRI',\n",
       " 'DT_VIRAL',\n",
       " 'GRAV_AST',\n",
       " 'GRAV_CONV',\n",
       " 'GRAV_HEMAT',\n",
       " 'GRAV_HIPOT',\n",
       " 'GRAV_INSUF',\n",
       " 'GRAV_MELEN',\n",
       " 'GRAV_METRO',\n",
       " 'GRAV_MIOC',\n",
       " 'GRAV_PULSO',\n",
       " 'GRAV_SANG',\n",
       " 'HISTOPA_N',\n",
       " 'HOSPITALIZ',\n",
       " 'IDENT_MICR',\n",
       " 'ID_BAIRRO',\n",
       " 'ID_GEO1',\n",
       " 'ID_MN_RESI',\n",
       " 'ID_OCUPA_N',\n",
       " 'ID_REGIONA',\n",
       " 'ID_RG_RESI',\n",
       " 'ID_UNIDADE',\n",
       " 'IMUNOH_N',\n",
       " 'NM_BAIRRO',\n",
       " 'NM_REFEREN',\n",
       " 'NOBAIINF',\n",
       " 'NU_IDADE_N',\n",
       " 'NU_NOTIFIC',\n",
       " 'RESUL_NS1',\n",
       " 'RESUL_PRNT',\n",
       " 'RESUL_SORO',\n",
       " 'RESUL_VI_N',\n",
       " 'RES_CHIKS1',\n",
       " 'RES_CHIKS2',\n",
       " 'SEM_PRI',\n",
       " 'SG_UF_NOT',\n",
       " 'TEL_HOSP',\n",
       " 'TPAUTOCTO'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df) - set(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RENAL</th>\n",
       "      <th>ALRM_HIPOT</th>\n",
       "      <th>GRAV_HEMAT</th>\n",
       "      <th>CS_FLXRET</th>\n",
       "      <th>ID_BAIRRO</th>\n",
       "      <th>ACIDO_PEPT</th>\n",
       "      <th>VOMITO</th>\n",
       "      <th>GRAV_ENCH</th>\n",
       "      <th>HEPATOPAT</th>\n",
       "      <th>ID_DISTRIT</th>\n",
       "      <th>...</th>\n",
       "      <th>LEUCOPENIA</th>\n",
       "      <th>DDD_HOSP</th>\n",
       "      <th>GRAV_PULSO</th>\n",
       "      <th>EVOLUCAO</th>\n",
       "      <th>TEL_HOSP</th>\n",
       "      <th>DT_SORO</th>\n",
       "      <th>FEBRE</th>\n",
       "      <th>DOR_COSTAS</th>\n",
       "      <th>ID_GEO2</th>\n",
       "      <th>CLASSI_FIN_BINARIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RENAL  ALRM_HIPOT  GRAV_HEMAT  CS_FLXRET  ID_BAIRRO  ACIDO_PEPT  VOMITO  \\\n",
       "0   -1.0        -1.0        -1.0        0.0       -1.0        -1.0    -1.0   \n",
       "1   -1.0        -1.0        -1.0        0.0        6.0        -1.0    -1.0   \n",
       "2    2.0        -1.0        -1.0        1.0      192.0         2.0     2.0   \n",
       "3   -1.0        -1.0        -1.0        0.0       24.0        -1.0    -1.0   \n",
       "4   -1.0        -1.0        -1.0        0.0       -1.0        -1.0    -1.0   \n",
       "\n",
       "   GRAV_ENCH  HEPATOPAT  ID_DISTRIT  ...  LEUCOPENIA  DDD_HOSP  GRAV_PULSO  \\\n",
       "0       -1.0       -1.0        -1.0  ...        -1.0      -1.0        -1.0   \n",
       "1       -1.0       -1.0        -1.0  ...        -1.0      -1.0        -1.0   \n",
       "2       -1.0        2.0        -1.0  ...         2.0      -1.0        -1.0   \n",
       "3       -1.0       -1.0        -1.0  ...        -1.0      -1.0        -1.0   \n",
       "4       -1.0       -1.0        -1.0  ...        -1.0      -1.0        -1.0   \n",
       "\n",
       "   EVOLUCAO  TEL_HOSP              DT_SORO  FEBRE  DOR_COSTAS  ID_GEO2  \\\n",
       "0      -1.0      -1.0 -9223372036854775808   -1.0        -1.0     -1.0   \n",
       "1      -1.0      -1.0 -9223372036854775808   -1.0        -1.0     -1.0   \n",
       "2       1.0      -1.0 -9223372036854775808    2.0         2.0     -1.0   \n",
       "3      -1.0      -1.0 -9223372036854775808   -1.0        -1.0     -1.0   \n",
       "4      -1.0      -1.0 -9223372036854775808   -1.0        -1.0     -1.0   \n",
       "\n",
       "   CLASSI_FIN_BINARIO  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 1.0  \n",
       "3                 1.0  \n",
       "4                 0.0  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549797, 116)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549797, 81)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RENAL', 'ALRM_HIPOT', 'GRAV_HEMAT', 'CS_FLXRET', 'ID_BAIRRO',\n",
       "       'ACIDO_PEPT', 'VOMITO', 'GRAV_ENCH', 'HEPATOPAT', 'ID_DISTRIT',\n",
       "       ...\n",
       "       'LEUCOPENIA', 'DDD_HOSP', 'GRAV_PULSO', 'EVOLUCAO', 'TEL_HOSP',\n",
       "       'DT_SORO', 'FEBRE', 'DOR_COSTAS', 'ID_GEO2', 'CLASSI_FIN_BINARIO'],\n",
       "      dtype='object', length=116)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CLASSI_FIN', 'CS_SEXO', 'ID_OCUPA_N', 'NM_BAIRRO', 'NM_REFEREN', 'NOBAIINF'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df) - set(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_NOTIFIC</th>\n",
       "      <th>DT_NOTIFIC</th>\n",
       "      <th>SG_UF_NOT</th>\n",
       "      <th>ID_REGIONA</th>\n",
       "      <th>ID_UNIDADE</th>\n",
       "      <th>DT_SIN_PRI</th>\n",
       "      <th>SEM_PRI</th>\n",
       "      <th>NU_IDADE_N</th>\n",
       "      <th>CS_SEXO</th>\n",
       "      <th>CS_GESTANT</th>\n",
       "      <th>...</th>\n",
       "      <th>GRAV_INSUF</th>\n",
       "      <th>GRAV_HIPOT</th>\n",
       "      <th>GRAV_HEMAT</th>\n",
       "      <th>GRAV_MELEN</th>\n",
       "      <th>GRAV_METRO</th>\n",
       "      <th>GRAV_SANG</th>\n",
       "      <th>GRAV_AST</th>\n",
       "      <th>GRAV_MIOC</th>\n",
       "      <th>DT_GRAV</th>\n",
       "      <th>IDENT_MICR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>1457136000000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>2498731.0</td>\n",
       "      <td>1456876800000000000</td>\n",
       "      <td>201609</td>\n",
       "      <td>3009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298</td>\n",
       "      <td>1455494400000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>3280969.0</td>\n",
       "      <td>1455408000000000000</td>\n",
       "      <td>201607</td>\n",
       "      <td>4039.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5082</td>\n",
       "      <td>1458864000000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>2800527.0</td>\n",
       "      <td>1458777600000000000</td>\n",
       "      <td>201612</td>\n",
       "      <td>4053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111262</td>\n",
       "      <td>1458777600000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>2706628.0</td>\n",
       "      <td>1458691200000000000</td>\n",
       "      <td>201612</td>\n",
       "      <td>4065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>1457827200000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>2498731.0</td>\n",
       "      <td>1457740800000000000</td>\n",
       "      <td>201610</td>\n",
       "      <td>4067.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NU_NOTIFIC           DT_NOTIFIC  SG_UF_NOT  ID_REGIONA  ID_UNIDADE  \\\n",
       "0         158  1457136000000000000         29      1381.0   2498731.0   \n",
       "1         298  1455494400000000000         29      1385.0   3280969.0   \n",
       "2        5082  1458864000000000000         29      1385.0   2800527.0   \n",
       "3      111262  1458777600000000000         29      1385.0   2706628.0   \n",
       "4         166  1457827200000000000         29      1381.0   2498731.0   \n",
       "\n",
       "            DT_SIN_PRI  SEM_PRI  NU_IDADE_N  CS_SEXO  CS_GESTANT  ...  \\\n",
       "0  1456876800000000000   201609      3009.0      1.0         6.0  ...   \n",
       "1  1455408000000000000   201607      4039.0      1.0         6.0  ...   \n",
       "2  1458777600000000000   201612      4053.0      0.0         5.0  ...   \n",
       "3  1458691200000000000   201612      4065.0      0.0         6.0  ...   \n",
       "4  1457740800000000000   201610      4067.0      0.0         6.0  ...   \n",
       "\n",
       "   GRAV_INSUF  GRAV_HIPOT  GRAV_HEMAT  GRAV_MELEN  GRAV_METRO  GRAV_SANG  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0        0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0        0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0        0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0        0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0        0.0   \n",
       "\n",
       "   GRAV_AST  GRAV_MIOC              DT_GRAV  IDENT_MICR  \n",
       "0       0.0        0.0 -9223372036854775808         4.0  \n",
       "1       0.0        0.0 -9223372036854775808         4.0  \n",
       "2       0.0        0.0 -9223372036854775808         4.0  \n",
       "3       0.0        0.0 -9223372036854775808         4.0  \n",
       "4       0.0        0.0 -9223372036854775808         4.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NU_NOTIFIC', 'DT_NOTIFIC', 'SG_UF_NOT', 'ID_REGIONA', 'ID_UNIDADE',\n",
       "       'DT_SIN_PRI', 'SEM_PRI', 'NU_IDADE_N', 'CS_SEXO', 'CS_GESTANT',\n",
       "       'CS_RACA', 'CS_ESCOL_N', 'ID_MN_RESI', 'ID_RG_RESI', 'ID_BAIRRO',\n",
       "       'NM_BAIRRO', 'ID_GEO1', 'NM_REFEREN', 'CS_ZONA', 'ID_OCUPA_N', 'FEBRE',\n",
       "       'CEFALEIA', 'VOMITO', 'CONJUNTVIT', 'ARTRITE', 'PETEQUIA_N',\n",
       "       'LEUCOPENIA', 'LACO', 'DOR_RETRO', 'DIABETES', 'HEMATOLOG', 'HEPATOPAT',\n",
       "       'RENAL', 'HIPERTENSA', 'ACIDO_PEPT', 'AUTO_IMUNE', 'DT_CHIK_S2',\n",
       "       'DT_PRNT', 'RES_CHIKS1', 'RES_CHIKS2', 'RESUL_PRNT', 'RESUL_SORO',\n",
       "       'DT_NS1', 'RESUL_NS1', 'DT_VIRAL', 'RESUL_VI_N', 'DT_PCR', 'HISTOPA_N',\n",
       "       'IMUNOH_N', 'HOSPITALIZ', 'DT_INTERNA', 'DDD_HOSP', 'TEL_HOSP',\n",
       "       'TPAUTOCTO', 'COUFINF', 'COPAISINF', 'CO_BAINF', 'NOBAIINF',\n",
       "       'CLASSI_FIN', 'DOENCA_TRA', 'CLINC_CHIK', 'DT_OBITO', 'ALRM_HIPOT',\n",
       "       'ALRM_PLAQ', 'ALRM_VOM', 'ALRM_SANG', 'ALRM_HEMAT', 'ALRM_HEPAT',\n",
       "       'DT_ALRM', 'GRAV_PULSO', 'GRAV_CONV', 'GRAV_INSUF', 'GRAV_HIPOT',\n",
       "       'GRAV_HEMAT', 'GRAV_MELEN', 'GRAV_METRO', 'GRAV_SANG', 'GRAV_AST',\n",
       "       'GRAV_MIOC', 'DT_GRAV', 'IDENT_MICR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2['CS_SEXO'] = df['CS_SEXO'].mode()[0]\n",
    "d2['ID_OCUPA_N'] = df['ID_OCUPA_N'].mode()[0]\n",
    "d2['NM_BAIRRO'] = df['NM_BAIRRO'].mode()[0]\n",
    "d2['NM_REFEREN'] = df['NM_REFEREN'].mode()[0]\n",
    "d2['NOBAIINF'] = df['NOBAIINF'].mode()[0]\n",
    "d2['CLASSI_FIN'] = df['CLASSI_FIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "Name: CS_SEXO, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CS_SEXO'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values: ['CLASSI_FIN']\n"
     ]
    }
   ],
   "source": [
    "columns_with_nan = d2.columns[d2.isna().any()].tolist()\n",
    "print(\"Columns with NaN values:\", columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d2[df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549797, 81)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['CLASSI_FIN'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.dropna(subset=['CLASSI_FIN'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516653, 81)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = d2['CLASSI_FIN']\n",
    "x = d2.drop(['CLASSI_FIN'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.plot_metrics(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
